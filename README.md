# AfterburnerSQL ![Логотип проекта](/frontend/src/assets/afterburner.png)

*Доброго времен суток, всем кто это читает. Вашему вниманию представляется автоматизированный обработчик SQL запросов под названием "**AfterburnerSQL**"*

# Установка

Скачайте репозиторий из *GitHub: https://github.com/K-Team-Coders/AfterburnerSQL* или *GitLab: https://git.codenrock.com/skolkovo-hack-2022/cnrprod-team-23883/rostelekom-task/-/tree/lead/*

# Запуск приложения через Docker

Откройте терминал в корне проекта, пропишите команду `docker-compose up -d`

Через некоторое время можно зайти в браузер по адресу *http://localhost:8080/*

# Запуск приложения вручную

#### Backend

Откройте терминал в папке ***backend***, выполните команды:

`python -m venv venv`

`venv\Scripts\activate`

`pip install -r requirements.txt`

Вы создали виртуальное окружение и загрузили необходимые библиотеки, теперь можно запустить backend-часть этого проекта

В папке backend, выполнить

`python manage.py runserver`

#### Frontend

Откройте терминал в папке ***frontend***, выполните команды:

`npm install`

`npm run serve`

После этого frontend-часть этого проекта будет доступна либо на http://localhost:8080/, либо на http://localhost:8081/

### Математическая составляющая проекта и как это работает

Для поиска статистических составляющих задачи мы использовали поиски по датафреймам библиотеки pandas с помощью быстрых *lambda*-функций.

Данный метод является наибыстрейшим так как: для решения задачи подсчета количества использования в отношениях аттрибута $N$ и аттрибута $N+1$ необходимо $t^{2}$ времени (задача перебора). Наибыстрейшими для python являются именно *lambda*-функции.

### Задача предсказания времени исполнения SQL-запроса (задача со звёздочкой)

В ходе выполнения работы по поиску метода, были получены следующие результаты:

1) Данные относительно обезличенных запросов сильно зашумлены (для одинаковых запросов время выполнения взято разное). Предположительно, это происходит из-за того что данные реальны, а значит к инфраструктуре в какие-то моменты было больше обращений, в какие-то меньше. Отсюда и время выполнения разное.
2) Есть *NaN*, то есть невалидные запросы (*NaN* в таблице).
3) Использован метод NLP для предсказания времени выполнения запроса на основе закодирования тела запроса в тензор. Результаты в виду зашумления неточные. Очень высокое *СКО* ~= 6145. В виду этого требуется обучение в нормальном режиме работы
4) Использован метод векторизации подсчета количества операторов для определения ошибки. Результат лучше, но из-за шумов, *СКО* получилось ~=1265.

### Выводы по работе и дальнейшие перспективы

1) Результат работы алгоритма на 600 тыс. запросов представлен в файлах *loguser_result.csv* и *tables_result.csv.* В дальнейшем будет разработана страница отчета для визуализации (рекомендована сортировка по нахождению аномалий относительно центра масс на скаттере)
2) Дообучение на адекватном режиме работы БД и создание дополнительной метки (работает нормально/работает в нагруженном состоянии)

## API

Весь API представлен в файлах **views.py** и **urls.py** Django - приложения.

API к моделям предполагает использование sql-query в GET-запросе по адресам:

1) *http://127.0.0.1/main/predict_query_time_execution/ваш_запрос/*
2) *http://127.0.0.1/main/predict_query_time_execution_operators/ваш_запрос/*
3) *http://127.0.0.1/main/predictQueryResponseTimeDesicionTree/[в](str:query)аш_запрос/*

То есть приложение можно использовать в любых проектах, просто по ссылке передавая sql-query в виде строки.
