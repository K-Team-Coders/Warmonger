{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1584b9e3",
   "metadata": {},
   "source": [
    "### Импорт библов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a579a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from pymystem3 import Mystem\n",
    "mystem = Mystem() \n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from collections import Counter \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.utils import shuffle\n",
    "import string\n",
    "lst_stopwords = nltk.corpus.stopwords.words('russian')\n",
    "lst_stopwords.extend(['…', '«', '»', '...'])\n",
    "nlp = spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992fdaf1",
   "metadata": {},
   "source": [
    "### Прочти данные в таком виде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb0bd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Фото: Виктор Чумаков / Пресс-служба судостроит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Фото:  Drew Coffman / Unsplash Андрей Ставицки...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Фото: TECHSPOT Андрей Ставицкий Китайская комп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ото: Pixabay Марина Совина Бывший сотрудник Бе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Фото: Kay Nietfeld / Globallookpress.com Марин...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Фото: Виктор Чумаков / Пресс-служба судостроит...\n",
       "1  Фото:  Drew Coffman / Unsplash Андрей Ставицки...\n",
       "2  Фото: TECHSPOT Андрей Ставицкий Китайская комп...\n",
       "3  ото: Pixabay Марина Совина Бывший сотрудник Бе...\n",
       "4  Фото: Kay Nietfeld / Globallookpress.com Марин..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3fb067",
   "metadata": {},
   "source": [
    "### функции предобраб текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83129c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, tokenizer, stopwords):\n",
    "\n",
    "    text = str(text).lower()  \n",
    "    text = re.sub(r\"\\[(.*?)\\]\", \"\", text)  \n",
    "    text = re.sub(r\"\\s+\", \" \", text)  \n",
    "    text = re.sub(r\"\\w+…|…\", \"\", text)  \n",
    "    text = re.sub(r\"(?<=\\w)-(?=\\w)\", \" \", text)  \n",
    "    text = re.sub(\n",
    "        f\"[{re.escape(string.punctuation)}]\", \"\", text\n",
    "    )  \n",
    "\n",
    "    tokens = tokenizer(text)  \n",
    "    tokens = [t for t in tokens if not t in lst_stopwords]  \n",
    "    tokens = [\"\" if t.isdigit() else t for t in tokens]  \n",
    "    tokens = [t for t in tokens if len(t) > 1] \n",
    "    return tokens\n",
    "def prep_tokens(df_raw):\n",
    "    text_columns = ['text']\n",
    "    #df_raw['content'] = df_raw['content'].fillna(\" \")\n",
    "    for col in text_columns:\n",
    "        df_raw[col] = df_raw[col].astype(str)\n",
    "    # создаем текст основанный на content title и tag\n",
    "    df_raw[\"text\"] = df_raw[text_columns].apply(lambda x: \" | \".join(x), axis=1)\n",
    "    df_raw[\"tokens\"] = df_raw[\"text\"].map(lambda x: clean_text(x, word_tokenize, lst_stopwords))\n",
    "    _, idx = np.unique(df_raw[\"tokens\"], return_index=True)\n",
    "    df_raw = df_raw.iloc[idx, :]\n",
    "\n",
    "    # Remove empty values\n",
    "    df_raw = df_raw.loc[df_raw.tokens.map(lambda x: len(x) > 0), [\"text\", \"tokens\"]]\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7a06cb",
   "metadata": {},
   "source": [
    "### Получи токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f84ac0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ото: Pixabay Марина Совина Бывший сотрудник Бе...</td>\n",
       "      <td>[ото, pixabay, марина, совина, бывший, сотрудн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Фото:  Drew Coffman / Unsplash Андрей Ставицки...</td>\n",
       "      <td>[фото, drew, coffman, unsplash, андрей, ставиц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Фото: Kay Nietfeld / Globallookpress.com Марин...</td>\n",
       "      <td>[фото, kay, nietfeld, globallookpresscom, мари...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Фото: TECHSPOT Андрей Ставицкий Китайская комп...</td>\n",
       "      <td>[фото, techspot, андрей, ставицкий, китайская,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Фото: Виктор Чумаков / Пресс-служба судостроит...</td>\n",
       "      <td>[фото, виктор, чумаков, пресс, служба, судостр...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "3  ото: Pixabay Марина Совина Бывший сотрудник Бе...   \n",
       "1  Фото:  Drew Coffman / Unsplash Андрей Ставицки...   \n",
       "4  Фото: Kay Nietfeld / Globallookpress.com Марин...   \n",
       "2  Фото: TECHSPOT Андрей Ставицкий Китайская комп...   \n",
       "0  Фото: Виктор Чумаков / Пресс-служба судостроит...   \n",
       "\n",
       "                                              tokens  \n",
       "3  [ото, pixabay, марина, совина, бывший, сотрудн...  \n",
       "1  [фото, drew, coffman, unsplash, андрей, ставиц...  \n",
       "4  [фото, kay, nietfeld, globallookpresscom, мари...  \n",
       "2  [фото, techspot, андрей, ставицкий, китайская,...  \n",
       "0  [фото, виктор, чумаков, пресс, служба, судостр...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data=prep_tokens(df)\n",
    "prep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0ec2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "###создаем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f936b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = prep_data[\"text\"].values\n",
    "tokenized_docs = prep_data[\"tokens\"].values\n",
    "vocab = Counter()\n",
    "for token in tokenized_docs:\n",
    "    vocab.update(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ddaf5",
   "metadata": {},
   "source": [
    "### Векторизируем слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64979bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b4954fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=prep_data['tokens'].values, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "840c7f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_docs= vectorize(prep_data['tokens'], model=model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9122a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ото: Pixabay Марина Совина Бывший сотрудник Бе...</td>\n",
       "      <td>[ото, pixabay, марина, совина, бывший, сотрудн...</td>\n",
       "      <td>[-0.0009992489, 0.0013703133, -0.0002628915, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Фото:  Drew Coffman / Unsplash Андрей Ставицки...</td>\n",
       "      <td>[фото, drew, coffman, unsplash, андрей, ставиц...</td>\n",
       "      <td>[0.00012650588, -0.0009367504, -0.00037640653,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Фото: Kay Nietfeld / Globallookpress.com Марин...</td>\n",
       "      <td>[фото, kay, nietfeld, globallookpresscom, мари...</td>\n",
       "      <td>[7.635207e-05, -0.00078705803, 0.0006089282, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Фото: TECHSPOT Андрей Ставицкий Китайская комп...</td>\n",
       "      <td>[фото, techspot, андрей, ставицкий, китайская,...</td>\n",
       "      <td>[-0.00031375713, 0.00039977144, 0.00052372174,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Фото: Виктор Чумаков / Пресс-служба судостроит...</td>\n",
       "      <td>[фото, виктор, чумаков, пресс, служба, судостр...</td>\n",
       "      <td>[-9.7775526e-05, 0.0007715449, -0.0001367061, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "3  ото: Pixabay Марина Совина Бывший сотрудник Бе...   \n",
       "1  Фото:  Drew Coffman / Unsplash Андрей Ставицки...   \n",
       "4  Фото: Kay Nietfeld / Globallookpress.com Марин...   \n",
       "2  Фото: TECHSPOT Андрей Ставицкий Китайская комп...   \n",
       "0  Фото: Виктор Чумаков / Пресс-служба судостроит...   \n",
       "\n",
       "                                              tokens  \\\n",
       "3  [ото, pixabay, марина, совина, бывший, сотрудн...   \n",
       "1  [фото, drew, coffman, unsplash, андрей, ставиц...   \n",
       "4  [фото, kay, nietfeld, globallookpresscom, мари...   \n",
       "2  [фото, techspot, андрей, ставицкий, китайская,...   \n",
       "0  [фото, виктор, чумаков, пресс, служба, судостр...   \n",
       "\n",
       "                                             vectors  \n",
       "3  [-0.0009992489, 0.0013703133, -0.0002628915, 0...  \n",
       "1  [0.00012650588, -0.0009367504, -0.00037640653,...  \n",
       "4  [7.635207e-05, -0.00078705803, 0.0006089282, -...  \n",
       "2  [-0.00031375713, 0.00039977144, 0.00052372174,...  \n",
       "0  [-9.7775526e-05, 0.0007715449, -0.0001367061, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data['vectors'] =vectorized_docs\n",
    "prep_data.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6c32d",
   "metadata": {},
   "source": [
    "### получаем класетры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad399bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbkmeans_clusters(X, k, mb=500, print_silhouette_values=False):\n",
    "\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=mb).fit(X)\n",
    "    print(f\"For n_clusters = {k}\")\n",
    "    print(f\"Silhouette coefficient: {silhouette_score(X, km.labels_):0.2f}\")\n",
    "    print(f\"Inertia:{km.inertia_}\")\n",
    "\n",
    "    if print_silhouette_values:\n",
    "        sample_silhouette_values = silhouette_samples(X, km.labels_)\n",
    "        print(f\"Silhouette values:\")\n",
    "        silhouette_values = []\n",
    "        for i in range(k):\n",
    "            cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "            silhouette_values.append(\n",
    "                (\n",
    "                    i,\n",
    "                    cluster_silhouette_values.shape[0],\n",
    "                    cluster_silhouette_values.mean(),\n",
    "                    cluster_silhouette_values.min(),\n",
    "                    cluster_silhouette_values.max(),\n",
    "                )\n",
    "            )\n",
    "        silhouette_values = sorted(\n",
    "            silhouette_values, key=lambda tup: tup[2], reverse=True\n",
    "        )\n",
    "        for s in silhouette_values:\n",
    "            print(\n",
    "                f\"    Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\"\n",
    "            )\n",
    "    return km, km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "569920dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### функция получения кластеров k - количествоо кластеров, X данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4c389e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 3\n",
      "Silhouette coefficient: -0.04\n",
      "Inertia:8.285716700170844e-05\n",
      "Silhouette values:\n",
      "    Cluster 1: Size:1 | Avg:0.00 | Min:0.00 | Max: 0.00\n",
      "    Cluster 2: Size:1 | Avg:0.00 | Min:0.00 | Max: 0.00\n",
      "    Cluster 0: Size:3 | Avg:-0.07 | Min:-0.08 | Max: -0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jora\\Desktop\\hack_0912\\venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clustering, cluster_labels = mbkmeans_clusters(prep_data['vectors'].tolist(),k=3, print_silhouette_values=True)\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": prep_data[\"text\"].values,\n",
    "    \"tokens\": [\" \".join(text) for text in tokenized_docs],\n",
    "    \"cluster\": cluster_labels\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e40d2e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые популярные темы в кластере:\n",
      "{0: 'министерстве герц преступлениями украине это ', 1: 'apple смартфонов ставицкий базе nothing ', 2: 'заливе адмирал игорь фрегат обороны '}\n"
     ]
    }
   ],
   "source": [
    "print(\"Самые популярные темы в кластере:\")\n",
    "k=3 # количесвто класетров ходных\n",
    "slov1={}\n",
    "for i in range(k):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=5)\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "        slov1[i]=tokens_per_cluster\n",
    "print(slov1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3bf696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Андрей Ставицкий (PER)\n",
      "Основатель (PER)\n",
      "Nothing (ORG)\n",
      "Apple (ORG)\n",
      "CNBC (ORG)\n",
      "Nothing (ORG)\n",
      "OnePlus (ORG)\n",
      "Карл Пэй (PER)\n",
      "Apple (ORG)\n",
      "IT-гиганта (ORG)\n",
      "Apple (ORG)\n",
      "-------------\n",
      "Виктор Чумаков (PER)\n",
      "Северная верфь (ORG)\n",
      "РИА Новости (ORG)\n",
      "Даниил Иринин Фрегат (PER)\n",
      "Финском заливе (LOC)\n",
      "Балтийского моря (LOC)\n",
      "Министерстве обороны (ORG)\n",
      "России (LOC)\n",
      "РИА Новости (ORG)\n",
      "Военно-морским флотом (ORG)\n",
      "Николаю Евменову (PER)\n",
      "Северная верфь (ORG)\n",
      "Балтийского флота (ORG)\n",
      "ТАСС (ORG)\n",
      "Северного флота (ORG)\n",
      "России (LOC)\n",
      "Адмирал Горшков (PER)\n",
      "Кронштадтский морской завод (ORG)\n",
      "Северной верфи (ORG)\n",
      "Игорь Орлов (PER)\n",
      "-------------\n",
      "TECHSPOT (ORG)\n",
      "Андрей Ставицкий (PER)\n",
      "BOE (ORG)\n",
      "TechSpot (ORG)\n",
      "Китае (LOC)\n",
      "BOE (ORG)\n",
      "BOE (ORG)\n",
      "AMD Ryzen (ORG)\n",
      "Nvidia RTX (ORG)\n",
      "Valorant (ORG)\n",
      "TechSpot (ORG)\n",
      "BOE (ORG)\n",
      "Asus (ORG)\n",
      "Nvidia (ORG)\n",
      "Чек Индекс (ORG)\n",
      "ЮMoney (ORG)\n",
      "России (LOC)\n",
      "-------------\n",
      "Марина Совина (PER)\n",
      "Луганской народной республики (ЛНР) (LOC)\n",
      "Совместном центре контроля и координации вопросов (ORG)\n",
      "Украины (СЦКК) (LOC)\n",
      "Вооруженных сил Украины (ВСУ) (ORG)\n",
      "Алчевск (LOC)\n",
      "Кременную (PER)\n",
      "Алчевска (LOC)\n",
      "Индустриальный техникум (ORG)\n",
      "Донбасского государственного технического института (ORG)\n",
      "Россией (LOC)\n",
      "Владимир Рогов (PER)\n",
      "Запорожье (LOC)\n",
      "Киева (LOC)\n",
      "ВСУ (ORG)\n",
      "-------------\n",
      "Pixabay (ORG)\n",
      "Марина Совина Бывший (PER)\n",
      "Белого дома (LOC)\n",
      "Рональда Рейгана (PER)\n",
      "Пол Крейг Робертс (PER)\n",
      "Латвии (LOC)\n",
      "Украине (LOC)\n",
      "Вьетнаме (LOC)\n",
      "Вашингтона (LOC)\n",
      "США (LOC)\n",
      "Робертс (PER)\n",
      "США (LOC)\n",
      "Украине (LOC)\n",
      "Латвии (LOC)\n",
      "Эдгарс Ринкевичс (PER)\n",
      "Украине (LOC)\n",
      "МИД (ORG)\n",
      "Украины (LOC)\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "docs = prep_data[\"text\"].values\n",
    "tokenized_docs = prep_data[\"tokens\"].values\n",
    "vocab = Counter()\n",
    "for token in tokenized_docs:\n",
    "    vocab.update(token)\n",
    "\n",
    "test_cluster = 1\n",
    "most_representative_docs = np.argsort(\n",
    "    np.linalg.norm(vectorized_docs - clustering.cluster_centers_[test_cluster], axis=1)\n",
    ")\n",
    "for d in most_representative_docs[:10]:\n",
    "    doc = nlp(docs[d])\n",
    "\n",
    "# в переменной 'doc' теперь содержится обработанная версия текста\n",
    "# мы можем делать с ней все что угодно!\n",
    "# например, распечатать все обнаруженные именованные сущности\n",
    "    for entity in doc.ents:\n",
    "        print(f\"{entity.text} ({entity.label_})\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e548716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a995a25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
